\section{Methodology}
\label{sec:researchDesign}

In the following subsections we discuss data collection and analysis for the performed studies. For naming the studies, we follow the terminology for Software Engineering research strategies from Stol and Fitzgerald~\cite{Stol2015}.


%nomenclatura

%Experimental simulation
%Judgement task
%Field Study


\subsection{Experimental Simulation}
\label{sec:experiment}

%GQM
In this study, we investigate the use of
external contract expressions -- in particular, \contrajdoc{}, as showed in Section\ref{sec:approach} -- in simulated programming tasks, with respect to applicability and understandability, from the point of view of Java developers. 

\subsubsection{Participants}
\label{sec:expPart}

%recruitment
We selected participants among professional developers assigned to projects in the context of an major R\&D Institute in Brazil. Recruitment was carried out by invitation; from estimated 150 invited professionals, 24 of them accepted the call and then, later, received the assignment by e-mail. The only requirement was previous experience with Java. From the 24 recruited developers, 10 of them had computer science (or related) degrees, while the remaining were carrying out undergraduate studies in the field. 

%number of participants
Although the number of participants may seem too small for generalizing any conclusions, we expect the observations to be considered as an exploratory theory to be checked by future studies with larger samples.
For experimental simulations, our participant set is within the expected size~\cite{}.


\subsubsection{Study Design}
\label{sec:studyDesign}

%factors
Our experiment was designed to assess the effect of a given documentation approach on implementation tasks which depend on documented APIs. 
%factor 1
Participants are assigned to use a single documentation approach (Factor 1) from the following: plain Javadoc natural language, our Javadoc extension and formal contracts. Table~\ref{tab:factorsEmpStudy} displays the treatments for those two factors.
%factor 2
For each of those approaches, two kinds of task are considered (Factor 2): a \textit{Supplier} task, in which the participant must program the implementation of a Java API class, and a \textit{Client} task, which demands development of a client code for the API.
%factor 3
An additional variation we included regards the particular API assigned to an arbitrary participant (Factor 3): \textit{Stack} or \textit{Queue}. We chose to use simple and well-known interfaces trying to avoid the confounding effect that lack of knowledge could bring to the study.


\begin{table}[ht]
\caption{Factors and treatments of the empirical study.}
\label{tab:factorsEmpStudy}
\centering
\begin{tabular}{ll} \toprule
\bfseries Factors & \bfseries Treatments \\
\hline

\multirow{2}{*}{\textbf{Task}} & Client \\
& Supplier \\ \hline 

\multirow{3}{*}{\textbf{Approach}} & Javadoc extension \\
 & Javadoc \\
& formal contracts \\ \bottomrule
\end{tabular}
\end{table}

%design
We use a factorial design~\cite{wohlin}, randomly assigning participants to each combination of treatments; each triple
$<$approach, task, API$>$ is called a trial.
Since there are three documenting approaches, two tasks and two Java interfaces, there are 12 possible trials, so each of them was carried out by two participants, resulting in a balanced design. 
The assignment Participant -- Trial is performed by using a
completely randomized design in order to minimize bias.


\subsubsection{Experimental Procedure}
\label{sec:expProcedure}

The experiment was performed offline, i.e., participants received the experimental package via an online Survey
platform\footnote{An instance of the platform used is
available online: \url{https://www.formpl.us/form/5671648952844288}} that we use to collect the results.
% double blind process 
% An example of survey sent to the
% participants can be found online.\footnote{\url{https://goo.gl/forms/ySTsYfKSRcotLayk1}} 

The experimental package consisted of (i) a statement of consent, (ii) a pretest
questionnaire, (iii) instructions and materials to perform the experiment, and (iv) a post-test
questionnaire. 
The instructions contained what we expected from the participants: they were asked to perform an implementation task (a supplier or a client code) for the
provided API. Each participant received one of the following tasks: create a supplier code for
an API or a client code using the API methods.
We also asked each participant to fulfill a
pre-study questionnaire reporting their programming experience (with respect to Java and contract-based programming experience). 
%After filling in the questionnaire, we randomly assign a task.

During the assignment, participants were allowed to review additional information -- part of the experimental package -- about the assigned documentation approach. 
%the tasks 1
For \textit{Supplier} tasks, participants should have implemented variations of well-known stack or queue operations whose intended behaviour was documented as \contractjdoc{} expressions. The following example shows the contract for \lstinline!Queue.add!, written in plain Javadoc commentary.
%example
\begin{lstlisting}[basicstyle=\footnotesize\ttfamily,name=figxpi, frame=lines, mathescape=true]
/**
   * Inserts the specified account into the queue 
   * if it is possible to do so 
   * immediately without violating capacity 
   * restrictions, returning true upon 
   * success and throwing an AccountQueueException 
   * if no space is currently available.
   * @param acc - the account to be added. 
   *     Must not be null.
   * @return true if the operation occurs with success.
   * @throws AccountQueueException - if the queue is 
   *     full or the account is null.
   */
  public boolean add(Account acc) throws AccountQueueException;
\end{lstlisting}

%the tasks 2
Differently, \textit{Client} tasks were carried out based on textual descriptions, although any call to API should fulfill its external contracts, also presented using one of the three documentation options. Implementation of the API were provided as binaries, so, as a result, participants were not given access to the source code.
%post-study
Before sending the results back, we asked the participants to answer a a post-experiment questionnaire, in which we collected qualitative information about the developers' view of each task.

We performed a pilot with three developers in order to fit the questionnaires' structure.
%the way in which we make the data available for the developers. 
As a result, we changed the way of making the artifacts available to participants. 
At first, we were making the documented interface available in a link and the working dataset in another. 
Pilot participants highlighted this fact, indicating that a single package containing all Java classes should be located in a single URL.

\subsubsection{Research Method}
label{sec:labmethod}

%method for checking correctness
Each program sent by the participants were subjected to test suites specially implemented for checking whether every single contract was fulfilled.
For this purpose, we applied a feedback-oriented test generator for the external contracts~\cite{sac2017}, whose tests were then run against runtime assertions corresponding to those contracts.
As a result, we are able to classify each submission according to the number of contract-code inconsistencies.

%method for analysing questionnaire info
The answers from qualitative post-study questionnaire were subject to a simple content analysis, performed by two researchers, which held a joint session for agreement on the category for each response from the developers.


\subsection{Judgment Survey}
\label{sec:survey}

%goal, question, metric
The goal of the survey is to compare three documentation approaches (Javadoc text, Javadoc with contract expressions and formal contracts) with respect to understability, from the point of view of developers. 

\subsubsection{Participants}
\label{sec:surveyPart}

%who to survey - convenience sample
We selected participants by means of a non-probability  convenience sample~\cite{wohlin}. 
The survey link was sent to academic and professional mailing lists.
%snowball approach - contacts
In addition, our contacts were asked to follow a snowball approach, sending the survey to their respective
contact lists, increasing the sample and the number of participants in our study.
%number
The survey was open for three weeks (from June to July 2016) and received 142
answers (from an estimated total of 700 contacts who received the link -- approximately a 20\% response
rate). From the 142 participants, 51 (\~36\%) are professionals and 91 are computer science (and related topics) students.


\subsubsection{Design and Method}
\label{sec:surveyDes}

%survey method
For this study, we followed a quantitative method based on a web-based survey instrument, suited to measure opinions and behaviors in response to specific questions~\cite{refSurvey}, in a non-threatening way. 
%web-based survey
% double blind
% The questions were available as an online form\footnote{http://goo.gl/forms/XcEqvPH0Eq920jaA3}. 

%survey structure
The survey
instrument\footnote{\url{https://goo.gl/forms/8W9jUMGCavkkzDj12}} begins with a purpose of clarification along with a consent term.
Then, a characterization of the respondent is conducted by some questions related to Java experience and experience with contract-based programming. Next, the survey is presented: links for three Java interfaces with each one documented in a different approach is showed, then some questions related to the understanding of the behavior of a class implementing the interfaces based on the comments available is asked. 

%likert scale
We used Likert-scale questions. In two questions we ask the developers to choose the most understandable documentation approach: one specific -- related to the provided interface; and one general, concerning the use of the approach in a general
context.

%pilot study
We also conducted a pilot concerning the questions and the structure of the programs being used. The pilot consists in asking three Java
developers to test the setup for the survey, allowing us to validate the survey's questions and structure. The developers who participated, however, did not reported issues on the structure that we used for presenting the needed data for the participation in the study.

%methods
Regarding quantitative methods, we applied Wilcoxon rank sum test~\cite{statistical} and Kruskal-Wallis rank sum test~\cite{statistical} for comparing the results for the different groups of participants. Regarding survey results, we applied Oneway ANOVA test~\cite{statistical}, The Tukey HSD~\cite{statistical} and pairwise comparisons using t tests with Bonferroni correction~\cite{statistical}; in addition, we applied Wilcoxon rank sum test with continuity correction tests.

\subsection{Case Study}
\label{sec:caseStudy}
%goal
This study aims at assessing the usefulness of contract expressions within Javadoc text, with respect to automation benefits, from the point of view of Java developers. 
%metric
We observe the results from applying adding contract expressions to \totalSystems{} real, Javadoc-rich open source systems; all their method-level Javadoc annotations are manually translated to contract expressions, before running tests looking for mismatches between specifications and actual method behavior.

\subsubsection{Systems Selection} 
\label{sec:systems}

%which systems
The case study was performed on a convenience sample: \totalSystems{} Javadoc-rich open source systems available at GitHub\footnote{\url{https://github.com/}} repository.
%criteria
They were selected based on the presence of method-level Javadoc annotations. 
Projects are searched by the following set of key phrases: ``must be'', ``must not be'', ``should
be'', ``should not be'', ``greater than'', ``not be null'', ``less than'' into Javadoc
comments.
After some visual filtering, we collected the five most important classes in
each system, based on overall dependence, and check whether those classes
contained method-level Javadoc comments for most of their methods. If so, the
system is selected. Finally, we checked whether the system presented a suite of
unit test, which are run during the case study to detect inconsistencies. We
were able to find four systems meeting these criteria, although we performed the
manual translation to six systems.

%system descriptions
While \texttt{ABC-Music-Player}\footnote{\url{https://github.com/deepakn94/ABC-Music-Player}}
plays music from an ABC file (part of a project assignment from MIT class
6.005), \texttt{Dishevelled}\footnote{\url{https://github.com/heuermh/dishevelled}} hosts
free and Open Source libraries for several user interface components and
supporting code, with emphasis on views and editors for complex data structures, like collections, sets, lists, maps, graphs, and
matrices; \texttt{Jenerics}\footnote{\url{https://github.com/mriedel/Jenerics}} is a general-purpose set of Java tools and templates library.
On the other hand, \texttt{OOP
Aufgabe3}\footnote{\url{https://github.com/rwilli/aufgabe3}} aims to manipulate
polygons. \texttt{SimpleShop}\footnote{\url{https://github.com/pase/simpleshop}} is an
electronical shopping system. In addition,
\texttt{Webprot\'{e}g\'{e}}\footnote{\url{https://github.com/protegeproject/webprotege}}
is a collaborative ontology development environment for the Web. Those systems amount to more than 190 KLOC. See Table~\ref{tab:Units} for details in
terms of code lines (LOC), total contract clauses (\#CC) we were able to write
-- following \cite{Estler-etal14} approach, in which the number of contract clauses is a proxy for contract complexity -- as split
into preconditions (\#Pre), postconditions (\#Post), and invariants (\#Inv).\footnote{The clauses
correspond to the contracts we applied in each system.}

%systems table
\begin{table}[ht]
\caption{Case study Systems. LOC shows the code lines (LOC), total contract clauses (\#CC), as split
into preconditions (\#Pre), postconditions (\#Post), and invariants (\#Inv)).}
\label{tab:Units}
\centering
\begin{tabular}{llllll}
\toprule
\bfseries System &  \bfseries LOC & 
\bfseries \#CC &  \bfseries \#Pre &  \bfseries \#Post &
 \bfseries \#Inv \\ \hline
ABC-Music-Player & 1,973 & 115 & 41 & 74 & 0 \\ 
Dishevelled & 110,577 & 2,655 & 1,411 & 1,250 & 0 \\ 
Jenerics & 2,538 & 190 & 105 & 85 & 0 \\ 
OOP Aufgabe3 & 353 & 54 & 28 & 26 & 0 \\
SimpleShop & 472 & 50 & 16 & 15 & 19 \\
Webprot\'{e}g\'{e} & 74,742 & 929 & 351 & 579 & 0 \\ \hline

 \bfseries Total &  \bfseries \totalCode{} &  \bfseries
\totalClauses{} &  \bfseries \totalPre{} &  \bfseries \totalPost{} &
 \bfseries \totalInv{}
\\
\bottomrule
\end{tabular}
\end{table}

%what is precondition, postcondition and invariant in javadoc
%criterio para a traducao
The manual translation abides by the following criteria: method-level comments were considered preconditions
if the comments establish some restriction over the method parameters.
For instance, \texttt{``@param notes - Should not be null and should be of length >= 2''} was
replaced by the following \contractjdoc{}-based expression \texttt{[notes != null \&\& notes.size() >= 2]}, and
postconditions that establish details on the return value of the
methods, e.g. \texttt{``@return Integer the number of edges. Is always >= 3''}
was replaced by \texttt{[@return >= 3]}. Class-level comments make up for
invariants when they describe properties over fields that must be maintained for
all methods of the class.

\subsubsection{Experimental Procedure and Research Method} 

%tasks
%translation
Three researchers applied \contractjdoc{} in \totalSystems{} existing open-source systems
available at GitHub. They followed a bottom-up approach for
writing the \contractjdoc{} contracts: the researchers started applying
\contractjdoc{} in the simplest methods and classes (or interfaces), following
up to the most complex. Contracts followed the Javadoc comments available in
natural language (in English) and some of them were inferred from the methods'
source code.
As result, they wrote \totalClauses{} contract clauses:
\totalPre{} preconditions, \totalPost{} postconditions, and \totalInv{} invariants (see
Table~\ref{tab:Units}).
Figure~\ref{fig:applicationProcess} presents the steps performed by the researchers when applying
\contractjdoc{} to the systems. The process is composed of four steps: 1) generation of the
contracts based on the natural language comments available (as showed in
Section~\ref{sec:systems}); 2) compilation of the contracts by means of
\contractjdocCompiler{} compiler, in order to generate the bytecode enriched
with assertions; 3) the test suite available in each system is run over the
contract-aware bytecode; 4) results of the test suite execution are analyzed and
conformance errors are investigated.

\begin{figure}[h]
\centering
\includegraphics[width=1.0\textwidth]{figs/ContractJDocProcess}
\caption{Steps for applying \contractjdoc{} to Javadoc-annotated systems.}
\label{fig:applicationProcess}
\end{figure}

%contract classification
Concerning the types of external contracts, we group the contracts according to
the approach introduced by XXXXX et al.~\cite{typeContracts}: application-specific contracts
(AppSpec.) -- the kind of contracts that enforce richer semantic properties;
% implications)
 common-case contracts (Com.Case) -- the kind of contracts that enforce
expected (common) program properties;
% methods do not modify unrelated variables; 
code-repetitive (Repet.) -- the kind of
contracts that repeat exact statements from the code.
% : that a method returns a

%experiment package - link
All systems used in this study are available in a replication
package.\footnote{\url{https://goo.gl/yO8or2}; in order to run the
\contractjdoc{} compiler, the folder \textit{aspectjml-lib} must be copied into the folder of each system.}
%when we consider an error
Concerning the verification performed after applying \contractjdoc{} contracts into the systems,
we used the test suites available with the purpose of identifying problems
(four out of \totalSystems{} projects have a test suite available).
Every test case that failed was investigated in order to find out if it was a conformance error in the system.

% applying dbcjdoc
As a secondary goal, the study allowed us to check the expressiveness of \contractjdoc{} and to
evaluate the effort related to adding contracts to existing systems.
In addition, we enhanced the compiler and added features in order to simplify
the process of applying \contractjdoc{} in existing projects.

