\section{Methodology}
\label{sec:researchDesign}

In this section, we explain the research design of each study performed for
evaluating the proposed approach.

\subsection{Case Study}
\label{sec:caseStudy}
%goal
This study aims at assessing \contractjdoc{} applicability, with respect to automation benefits, from the point of view of Java developers. 
%metric
We observe the results from applying \contractjdoc{} to \totalSystems{} real,
Javadoc-rich open source systems; all their method-level
Javadoc annotations are manually translated to \contractjdoc{}, before
running tests looking for mismatches between specifications and actual method
behavior.

\subsubsection{Systems Selection} 
\label{sec:systems}

%which systems
The case study was performed on a convenience sample: \totalSystems{}
Javadoc-rich open source systems available at GitHub\footnote{\url{https://github.com/}} repository.
%criteria
They were selected based on the presence of method-level Javadoc annotations. 
Projects are searched by the following set of key phrases: ``must be'', ``must not be'', ``should
be'', ``should not be'', ``greater than'', ``not be null'', ``less than'' into Javadoc
comments.
After some visual filtering, we collected the five most important classes in
each system, based on overall dependence, and check whether those classes
contained method-level Javadoc comments for most of their methods. If so, the
system is selected. Finally, we checked whether the system presented a suite of
unit test, which are run during the case study to detect inconsistencies. We
were able to find four systems meeting these criteria, although we performed the
manual translation to six systems.

%system descriptions
While \texttt{ABC-Music-Player}\footnote{\url{https://github.com/deepakn94/ABC-Music-Player}}
plays music from an ABC file (part of a project assignment from MIT class
6.005), \texttt{Dishevelled}\footnote{\url{https://github.com/heuermh/dishevelled}} hosts
free and Open Source libraries for several user interface components and
supporting code, with emphasis on views and editors for complex data structures, like collections, sets, lists, maps, graphs, and
matrices; \texttt{Jenerics}\footnote{\url{https://github.com/mriedel/Jenerics}} is a general-purpose set of Java tools and templates library.
On the other hand, \texttt{OOP
Aufgabe3}\footnote{\url{https://github.com/rwilli/aufgabe3}} aims to manipulate
polygons. \texttt{SimpleShop}\footnote{\url{https://github.com/pase/simpleshop}} is an
electronical shopping system. In addition,
\texttt{Webprot\'{e}g\'{e}}\footnote{\url{https://github.com/protegeproject/webprotege}}
is a collaborative ontology development environment for the Web. Those systems amount to more than 190 KLOC. See Table~\ref{tab:Units} for details in
terms of code lines (LOC), total contract clauses (\#CC) we were able to write
-- following \cite{Estler-etal14} approach, in which the number of contract clauses is a proxy for contract complexity -- as split
into preconditions (\#Pre), postconditions (\#Post), and invariants (\#Inv).\footnote{The clauses
correspond to the contracts we applied in each system.}

%systems table
\begin{table}[ht]
\caption{Case study Systems. LOC shows the code lines (LOC), total contract clauses (\#CC), as split
into preconditions (\#Pre), postconditions (\#Post), and invariants (\#Inv)).}
\label{tab:Units}
\centering
\begin{tabular}{llllll}
\toprule
\bfseries System &  \bfseries LOC & 
\bfseries \#CC &  \bfseries \#Pre &  \bfseries \#Post &
 \bfseries \#Inv \\ \hline
ABC-Music-Player & 1,973 & 115 & 41 & 74 & 0 \\ 
Dishevelled & 110,577 & 2,655 & 1,411 & 1,250 & 0 \\ 
Jenerics & 2,538 & 190 & 105 & 85 & 0 \\ 
OOP Aufgabe3 & 353 & 54 & 28 & 26 & 0 \\
SimpleShop & 472 & 50 & 16 & 15 & 19 \\
Webprot\'{e}g\'{e} & 74,742 & 929 & 351 & 579 & 0 \\ \hline

 \bfseries Total &  \bfseries \totalCode{} &  \bfseries
\totalClauses{} &  \bfseries \totalPre{} &  \bfseries \totalPost{} &
 \bfseries \totalInv{}
\\
\bottomrule
\end{tabular}
\end{table}

%what is precondition, postcondition and invariant in javadoc
%criterio para a traducao
The manual translation abides by the following criteria: method-level comments were considered preconditions
if the comments establish some restriction over the method parameters.
For instance, \texttt{``@param notes - Should not be null and should be of length >= 2''} was
replaced by the following \contractjdoc{}-based expression \texttt{[notes != null \&\& notes.size() >= 2]}, and
postconditions that establish details on the return value of the
methods, e.g. \texttt{``@return Integer the number of edges. Is always >= 3''}
was replaced by \texttt{[@return >= 3]}. Class-level comments make up for
invariants when they describe properties over fields that must be maintained for
all methods of the class.

\subsubsection{Experimental Procedure and Research Method} 

%tasks
%translation
Three researchers applied \contractjdoc{} in \totalSystems{} existing open-source systems
available at GitHub. They followed a bottom-up approach for
writing the \contractjdoc{} contracts: the researchers started applying
\contractjdoc{} in the simplest methods and classes (or interfaces), following
up to the most complex. Contracts followed the Javadoc comments available in
natural language (in English) and some of them were inferred from the methods'
source code.
As result, they wrote \totalClauses{} contract clauses:
\totalPre{} preconditions, \totalPost{} postconditions, and \totalInv{} invariants (see
Table~\ref{tab:Units}).
Figure~\ref{fig:applicationProcess} presents the steps performed by the researchers when applying
\contractjdoc{} to the systems. The process is composed of four steps: 1) generation of the
contracts based on the natural language comments available (as showed in
Section~\ref{sec:systems}); 2) compilation of the contracts by means of
\contractjdocCompiler{} compiler, in order to generate the bytecode enriched
with assertions; 3) the test suite available in each system is run over the
contract-aware bytecode; 4) results of the test suite execution are analyzed and
conformance errors are investigated.

\begin{figure}[h]
\centering
\includegraphics[width=1.0\textwidth]{figs/ContractJDocProcess}
\caption{Steps for applying \contractjdoc{} to Javadoc-annotated systems.}
\label{fig:applicationProcess}
\end{figure}

%contract classification
Concerning the kind of written contracts, we group the contracts according to
the approach of \cite{typeContracts}: application-specific contracts
(AppSpec.) -- the kind of contracts that enforce richer semantic properties;
% implications)
 common-case contracts (Com.Case) -- the kind of contracts that enforce
expected (common) program properties;
% methods do not modify unrelated variables; 
code-repetitive (Repet.) -- the kind of
contracts that repeat exact statements from the code.
% : that a method returns a

%experiment package - link
All systems with the contracts added in this study are available in a replication
package.\footnote{\url{https://goo.gl/yO8or2}; in order to run the
\contractjdoc{} compiler, the folder \textit{aspectjml-lib} must be copied into the folder of each system.}
%when we consider an error
Concerning the verification performed after applying \contractjdoc{} contracts into the systems,
we used the test suites available with the purpose of identifying problems
(four out of \totalSystems{} projects have a test suite available).
Every test case that failed was investigated in order to find out if it was a conformance error in the system.

% applying dbcjdoc
As a secondary goal, the study allowed us to check the expressiveness of \contractjdoc{} and to
evaluate the effort related to adding contracts to existing systems.
In addition, we enhanced the compiler and added features in order to simplify
the process of applying \contractjdoc{} in existing projects.

\subsection{Empirical Study}
\label{sec:experiment}

The goal of the empirical study is to investigate
\contractjdoc{}, for the purpose of evaluation with respect to readability and understandability, from the point of view of
developers in the context of Java programming language. The study presents two factors: the task performed by the
developer (task), and the documenting approach (approach).
% , and the experience level of the developer (experience level)
Those factors have the following treatments: client and supplier\footnote{By client, we mean a class calling the methods provided by an interface, and by supplier, we mean a class implementing the
interface.} -- for task; and Javadoc,
\contractjdoc{}, and JML -- for approach (see Table~\ref{tab:factorsEmpStudy}).

\begin{table}[ht]
\caption{Factors and treatments of the empirical study.}
\label{tab:factorsEmpStudy}
\centering
\begin{tabular}{ll} \toprule
\bfseries Factors & \bfseries Treatments \\
\hline

\multirow{2}{*}{\textbf{Task}} & Client \\
& Supplier \\ \hline 

\multirow{3}{*}{\textbf{Approach}} & \contractjdoc{} \\
 & Javadoc \\
& JML \\ \bottomrule
\end{tabular}
\end{table}

\subsubsection{Participants Recruitment}
\label{sec:expPart}

The subjects who took part in this experiment (called Participants
henceforth) were industry professionals and students from Brazil. Professionals
those who work or already have worked with programming to industry. Students those who have only academic
experience.

The recruitment was done in a convenience sample by the authors: we invited
professionals and students from our network. In total there were 24 participants
in the experiment: 10 industry professionals and 14 students. All participants'
experience includes a good knowledge of Java.


\subsubsection{Study Design}
\label{sec:studyDesign}

We addressed two factors: approach for commenting
source code, task to be performed; with the following treatments: Javadoc, \contractjdoc{}, and JML
-- for approach, and client and supplier -- for the task.
Moreover, we use two Java equivalent interfaces in this experiment: Stack and Queue.
We use a factorial design~\cite{wohlin},  randomly assigning subjects to each combination of the
treatments. For the purpose of this experiment, each triple
$<$approach, task, interface$>$ is called a trial (a combination of treatments).
Since there are three documenting approaches, two tasks and two Java interfaces,
the experiment counts with 12 trials. The assignment Participant --- trial is performed by using a
completely randomized design in order to not bias the results.
% 
% We balance the number of people in each trial because balancing simplifies and strengthens the statistical analysis of data
The experiment uses a balanced design, which means there is the same number of
participants in each trial~\cite{wohlin} -- two in our case.

\subsubsection{Experimental Procedure}
\label{sec:expProcedure}

The experiment was performed offline, i.e., participants received the
experimental material via an online Survey
platform\footnote{An instance
of the platform used is
available online: \url{https://www.formpl.us/form/5671648952844288}} that we use
to collect the results.
% double blind process 
% An example of survey sent to the
% participants can be found online.\footnote{\url{https://goo.gl/forms/ySTsYfKSRcotLayk1}} 
Each
participant received an experiment package, consisting of (i) a statement of consent, (ii) a pretest
questionnaire, (iii) instructions and materials to perform the experiment, and (iv) a post-test
questionnaire. Before the study, we explained to participants what we expected them to do during the
experiment: they were asked to perform an implementation task (a supplier or a client code) for the
provided interface. Each participant received one of the following tasks: create a supplier code for
an interface or a client code for using the interface methods.

Before starting the experiment, we asked each participant to fulfill a
pre-study questionnaire reporting their programming experience (with respect to Java and contract-based programming
experience). After filling in the questionnaire, we randomly selected a task for
each of them.

The first part of the experiment consists
on the following activities: (i) apply a questionnaire pre-experiment -- in order to collect
information on developers experience; (ii) give some kind of training on the documenting approach,
such as JML and \contractjdoc{}; (iii) ask them to execute the tasks -- for each developer will be
given one task for one approach with one Java interface; (iv) apply a post-experiment 
questionnaire -- in order to collect qualitative information about the developers' view of each task.

\subsubsection{Instrumentation}
\label{sec:expInstrumentation}

We performed a pilot with three Java developers in order to fit the
questions structure, the way in which we make the data
available for the developers. As a result, we changed the way of making the
working dataset available to the participants. Initially we were making the documented interface available in a link and the working dataset in another. The
answers to the pilot highlighted this fact and we decided to create a single package containing all
Java classes (all classes needed to the compilation of the code) related to the experiment in a
single URL.

\subsection{Comprehensibility Survey}
\label{sec:survey}

We conducted an exploratory study that involved data collection through a survey with Java
development professionals. 
%This section describes the survey design, participants, results and discussion.
%goal, question, metric
The goal of the survey is to compare three documentation approaches (Javadoc,
\contractjdoc{}, and JML) with respect to comprehensibility, from the point of view of developers. 

\subsubsection{Design}
\label{sec:surveyDes}

%survey method
For this study, we followed a quantitative method based on a web-based survey instrument, suited to
measure opinions and behaviors in response to specific questions~\cite{refSurvey}, in a non
threatening way. 
%web-based survey
% double blind
% The questions were available as an online form\footnote{http://goo.gl/forms/XcEqvPH0Eq920jaA3}. 

%survey structure
The survey
instrument\footnote{\url{https://goo.gl/forms/8W9jUMGCavkkzDj12}} begins with a
purpose of clarification along with a consent term.
Then, a characterization of the
respondent is conducted by some questions related to Java experience and experience with
contract-based programming. Next, the survey is presented: links for three Java interfaces with each
one documented in a different approach is showed, then some questions related to the understanding
of the behavior of a class implementing the interfaces based on the comments available is asked. 

%likert scale
We used Likert-scale questions. In two questions we ask the developers to
choose the most understandable documentation approach: one specific -- related
to the provided interface; and one general, concerning the use of the approach in a general
context.

%pilot study
We also conducted a pilot concerning the
questions and the structure of the programs being used. The pilot consists in asking three Java
developers to test the setup for the survey.
The pilot allowed us to validate the survey's questions and structure.
We did not have to change anything. The developers who participated did not reported issues on the structure that we
used for presenting the needed data for the participation in the study.


\subsubsection{Survey Participants}
\label{sec:surveyPart}

%who to survey - convenience sample
The survey participants are also extracted by means of a 
non-probability sampling technique -- convenience
sampling~\cite{wohlin}: the nearest and most convenient persons are selected as subjects. We send
the survey link to academic and professional mailing lists.
%snowball approach - contacts
In addition, our contacts made a snowball approach, sending the survey to their respective
contact lists, increasing the sample and the number of participants in our study.
%number
The survey was open for three weeks (from June to July 2016) and received 142
answers (from an estimated total of 700 who received the link, 20\% response
rate). From the 142, 51 are professionals and 91 are students.

\subsection{Statistical Methods}
\label{sec:statisticalMethods}

In our experiment, we applied Wilcoxon rank sum test~\cite{statistical} and Kruskal-Wallis rank sum test~\cite{statistical} for comparing the results according to our treatments. For the survey results, we applied Oneway ANOVA test~\cite{statistical}, The Tukey HSD~\cite{statistical} and pairwise comparisons using t tests
with Bonferroni correction~\cite{statistical}; in addition, we applied Wilcoxon rank sum test with continuity correction
tests.
