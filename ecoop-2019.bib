@article{Hoare1969,
abstract = {In this paper an attempt is made to explore the logical foundations of computer programming by use of techniques which were first applied in the study of geometry and have later been extended to other branches of mathematics. This involves the elucidation of sets of axioms and rules of inference which can be used in proofs of the properties of computer programs. Examples are given of such axioms and rules, and a formal proof of a simple theorem is displayed. Finally, it is argued that important advantages, both theoretical and practical, may follow from a pursuance of these topics.},
author = {Hoare, C. A. R.},
doi = {10.1145/363235.363259},
isbn = {0001-0782},
issn = {00010782},
journal = {Communications of the ACM},
mendeley-groups = {Ecoop contractJdoc},
pmid = {560945},
title = {{An axiomatic basis for computer programming}},
year = {1969}
}

@inproceedings{Dietrich2017,
abstract = {The use of formal contracts has long been advocated as an approach to develop programs that are provably correct. However, the reality is that adoption of contracts has been slow in practice. Despite this, the adoption of lightweight contracts - typically utilising runtime checking - has progressed. In the case of Java, built-in features of the language (e.g. assertions and exceptions) can be used for this. Furthermore, a number of libraries which facilitate contract checking have arisen. In this paper, we catalogue 25 techniques and tools for lightweight contract checking in Java, and present the results of an empirical study looking at a dataset extracted from the 200 most popular projects found on Maven Central, constituting roughly 351,034 KLOC. We examine (1) the extent to which contracts are used and (2) what kind of contracts are used. We then investigate how contracts are used to safeguard code, and study problems in the context of two types of substitutability that can be guarded by contracts: (3) unsafe evolution of APIs that may break client programs and (4) violations of Liskov's Substitution Principle (LSP) when methods are overridden. We find that: (1) a wide range of techniques and constructs are used to represent contracts, and often the same program uses different techniques at the same time; (2) overall, contracts are used less than expected, with significant differences between programs; (3) projects that use contracts continue to do so, and expand the use of contracts as they grow and evolve; and, (4) there are cases where the use of contracts points to unsafe subtyping (violations of Liskov Substitution Principle) and unsafe evolution.},
author = {Dietrich, Jens and Pearce, David J and Jezek, Kamil and Brada, Premek and Dietrich, Jens},
booktitle = {31st European Conference on Object-Oriented Programming (ECOOP 2017)},
doi = {10.4230/LIPIcs.ECOOP.2017.9},
isbn = {978-3-95977-035-4},
issn = {1868-8969},
mendeley-groups = {Ecoop contractJdoc},
title = {{Contracts in the Wild: A Study of Java Programs}},
year = {2017}
}


@inproceedings{Stol2015,
abstract = {Empirical research studies are the principal mech- anism through which the software engineering research commu- nity studies and learns from software engineering practice. The focus on empirical studies has increased significantly in the past decade, more or less coinciding with the emergence of evidence- based software engineering, an idea that was proposed in 2004. As a consequence, the software engineering community is familiar with a range of empirical methods. However, while several overviews exist of popular empirical research methods, such as case studies and experiments, we lack a ‘holistic' view of a more complete spectrum of research methods. Furthermore, while researchers will readily accept that all methods have inherent limitations, methods such as case study are still frequently critiqued for the lack of control that a researcher can exert in such a study, their use of qualitative data, and the limited generalizability that can be achieved. Controlled experiments are seen by many as yielding stronger evidence than case studies, but these can also be criticized due to the limited realism of the context in which they are conducted. We identify a holistic set of research methods and indicate their strengths and weaknesses in relation to various research elements.},
author = {Stol, Klaas-Jan and Fitzgerald, Brian},
booktitle = {2015 IEEE/ACM 3rd International Workshop on Conducting Empirical Studies in Industry},
doi = {10.1109/CESI.2015.15},
isbn = {978-1-4673-7028-8},
keywords = {Empirical research,research strategy,software engineering},
mendeley-groups = {Ecoop contractJdoc},
month = {may},
pages = {47--54},
publisher = {IEEE},
title = {{A Holistic Overview of Software Engineering Research Strategies}},
url = {http://ieeexplore.ieee.org/document/7167427/},
year = {2015}
}


@techreport{winkler99,
  author = {Winkler, William E.},
  institution = {U.S. Bureau of the Census, Washington, D.C.},
  number = {Statistical Research Report Series RR99/04},
  title = {The State of Record Linkage and Current Research Problems},
  year = 1999
}

@article{jaro,
 author = {Matthew A. Jaro},
 journal = {Journal of the American Statistical Association},
 number = {406},
 pages = {414-420},
 publisher = {[American Statistical Association, Taylor & Francis, Ltd.]},
 title = {Advances in Record-Linkage Methodology as Applied to Matching the 1985 Census of Tampa, Florida},
 volume = {84},
 year = {1989}
}

@Book{statistical,
  author = 	 {Kanji, G.},
  title = 	 {{100 Statistical Tests}},
  publisher = 	 {Sage},
  year = 	 {2006},
}

@article{confinedTypes,
 author = {Vitek, J. and Bokowski, B.},
 title = {Confined Types},
 journal = {SIGPLAN Not.},
 issue_date = {Oct. 1999},
 volume = {34},
 number = {10},
 month = oct,
 year = {1999},
 pages = {82--96},
 publisher = {ACM},
}

@techreport{cnl-def2,
 author = {Fuchs, N. and Schwitter, R.},
 title = {Specifying Logic Programs in Controlled Natural Language},
 year = {1995},
 institution = {University of Zurich},
}

@inproceedings{Scalabrino2017,
abstract = {—Program understanding plays a pivotal role in soft-ware maintenance and evolution: a deep understanding of code is the stepping stone for most software-related activities, such as bug fixing or testing. Being able to measure the understandability of a piece of code might help in estimating the effort required for a maintenance activity, in comparing the quality of alternative implementations, or even in predicting bugs. Unfortunately, there are no existing metrics specifically designed to assess the understandability of a given code snippet. In this paper, we perform a first step in this direction, by studying the extent to which several types of metrics computed on code, documentation, and developers correlate with code understandability. To perform such an investigation we ran a study with 46 participants who were asked to understand eight code snippets each. We collected a total of 324 evaluations aiming at assessing the perceived understandability, the actual level of understanding, and the time needed to understand a code snippet. Our results demonstrate that none of the (existing and new) metrics we considered is able to capture code understandability, not even the ones assumed to assess quality attributes strongly related with it, such as code readability and complexity.},
author = {Scalabrino, Simone and Bavota, Gabriele and Vendome, Christopher and Linares-Vasquez, Mario and Poshyvanyk, Denys and Oliveto, Rocco},
booktitle = {ASE 2017 - Proceedings of the 32nd IEEE/ACM International Conference on Automated Software Engineering},
doi = {10.1109/ASE.2017.8115654},
isbn = {9781538626849},
keywords = {Code understandability,Empirical study,Negative result,Software metrics},
mendeley-groups = {Ecoop contractJdoc},
title = {{Automatically assessing code understandability: How far are we?}},
year = {2017}
}


@MISC{jmlreference,
    author = {G. Leavens and E. Poll and C. Clifton and Y. Cheon and C. Ruby and D. Cok and P. M�ller and J. Kiniry and P. Chalin and D. Zimmerman and W. Dietl},
    title = {{JML Reference Manual}},
    year = {2013}
}

@inproceedings{docAnalysis,
 author = {Zhai, J. and Huang, J. and Ma, S. and Zhang, X. and Tan, L. and Zhao, J. and Qin, F.},
 title = {Automatic Model Generation from Documentation for Java API Functions},
 booktitle = {International Conference on Software Engineering},
 year = {2016},
 pages = {380--391},
 publisher = {ACM},
}

@book{refSurvey,
 author = {Dillman, D. and Smyth, J. and Christian, L.},
 title = {Internet, Phone, Mail, and Mixed-Mode Surveys: The Tailored Design Method},
 year = {2014},
 edition = {4th},
 publisher = {Wiley Publishing},
}

@InProceedings{ajmlc,
  author = 	 {H. Reb\^{e}lo and R. Lima and M. Corn\'{e}lio and G. Leavens and A. Mota and C. Oliveira},
  title = 	 {{Optimizing JML Features Compilation in ajmlc Using Aspect-Oriented Refactorings}},
  booktitle = {Brazilian Symposium on Programming Languages},
  year = 	 {2009},

}

@inproceedings{aspectjml,
 author = {Reb\^{e}lo, H. and Leavens, G. and Bagherzadeh, M. and Rajan, H. and Lima, R. and Zimmerman, D. and Corn{\'e}lio, M. and Th\"{u}m, T.},
 title = {AspectJML: Modular Specification and Runtime Checking for Crosscutting Contracts},
 booktitle = {International Conference on Modularity},
 year = {2014},
 pages = {157--168},
 publisher = {ACM},
}

@inproceedings{Rebelo-etal08,
 author = {Reb\^{e}lo, H. and Soares, S. and Lima, R. and Ferreira, L. and Corn{\'e}lio, M.},
 title = {Implementing Java Modeling Language Contracts with AspectJ},
 booktitle = {Proceedings of the 2008 ACM Symposium on Applied Computing},
 year = {2008},
 pages = {228--233},
 publisher = {ACM},
}

@inproceedings{Polikarpova-etal09,
 author = {Polikarpova, N. and Ciupa, I. and Meyer, B.},
 title = {A Comparative Study of Programmer-written and Automatically Inferred Contracts},
 booktitle = {International Symposium on Software Testing and Analysis},
 year = {2009},
 pages = {93--104},
 publisher = {ACM},
}


@inproceedings{Estler-etal14,
 author = {Estler, H. and Furia, C. and Nordio, M. and Piccioni, M. and Meyer, B.},
 title = {Contracts in Practice},
 booktitle = {International Symposium on Formal Methods},
 year = {2014},
 pages = {230--246},
 publisher = {Springer-Verlag New York, Inc.},
}

@Inbook{Parnas2011,
author="Parnas, D.",
title="Precise Documentation: The Key to Better Software",
bookTitle="The Future of Software Engineering",
year="2011",
publisher="Springer Berlin Heidelberg",
pages="125--148",
}

@incollection{Chalin06,
 author = {Chalin, P.},
 title = {Are Practitioners Writing Contracts?},
 booktitle = {Rigorous Development of Complex Fault-Tolerant Systems},
 editor = {Butler, Michael and Jones, Cliff B. and Romanovsky, Alexander and Troubitsyna, Elena},
 year = {2006},
 pages = {100--113},
 publisher = {Springer-Verlag},
}

@inproceedings{liveAPI,
 author = {Subramanian, S. and Inozemtseva, L. and Holmes, R.},
 title = {{Live API Documentation}},
 booktitle = {International Conference on Software Engineering},
 year = {2014},
 pages = {643--652},
 publisher = {ACM},
}

@Inproceedings {codeContractsPaper,
author       = {M. Barnett and M. F\"{a}hndrich and F. Logozzo},
booktitle = {Symposium on Applied Computing},
publisher    = {ACM},
title        = {{Embedded Contract Languages}},
year         = {2010},
pages = {2103--2110},
}

@Inproceedings {clousot,
author = {F\"{a}hndrich, M. and Logozzo, F.},
booktitle    = {International Conference on Formal Verification of Object-oriented Software},
publisher    = {Springer-Verlag},
title        = {{Static contract checking with Abstract Interpretation}},
year         = {2010},
pages = {10--30},
}

@article{autotest,
  author    = {B. Meyer and
               A. Fiva and
               I. Ciupa and
               A. Leitner and
               Y. Wei and
               E. Stapf},
  title     = {{Programs That Test Themselves}},
  pages={46-55},
  volume={42},
  number={9},
  journal   = {IEEE Computer},
  year      = {2009},
}

@inproceedings{artoo,
 author = {Ciupa, I. and Leitner, A. and Oriol, M. and Meyer, B.},
 title = {{ARTOO: Adaptive Random Testing for Object-oriented Software}},
 booktitle = {International Conference on Software Engineering},
 pages = {71--80},
 year = {2008},
 publisher = {ACM},
}

@InProceedings{jmlok2,
  author = 	 {A. Milanez and D. Sousa and T. Massoni and R. Gheyi},
  title = 	 {{JMLOK2: A tool for detecting and categorizing nonconformances}},
  booktitle = {Brazilian Conference on Software: Theory and Practice (Tools session)},
  pages = {69--76},
  year = 	 {2014},
}

@INPROCEEDINGS{randoop-icse07,
  author = {C. Pacheco and S. K. Lahiri and M. D. Ernst and T. Ball},
  title = {{Feedback-Directed Random Test Generation}},
  booktitle = {Proceeedings of the 29th International Conference on Software Engineering},
  year = {2007},
  pages = {75-84},
  publisher = {IEEE Computer Society}
}

@article{eiffel,
 author = {Meyer, B.},
 title = {{Eiffel: programming for reusability and extendibility}},
 journal = {ACM SIGPLAN Notices},
 pages = {85--94},
 year = {1987},
 volume = {22},
 number = {2},
 publisher = {ACM},
}

@inproceedings{crossedDesign,
 author = {Kitchenham, B. and Fry, J. and Linkman, S.},
 title = {The Case Against Cross-Over Designs in Software Engineering},
 booktitle = {Proceedings of the Eleventh Annual International Workshop on Software Technology and Engineering Practice},
 year = {2003},
 pages = {65--67},
 publisher = {IEEE Computer Society},
}

@book{wohlin,
  author = {Wohlin, C. and Runeson, P. and H\"ost, M. and Ohlsson, M. and Regnell, B.},
  publisher = {Springer},
  title = {Experimentation in Software Engineering.},
  year = 2012,
  edition = {1st},
}

@MastersThesis{myDissertation,
  author = 	 {A. F. Milanez},
  title = 	 {{Enhancing Conformance Checking for Contract-Based Programs}},
  school = 	 {Federal University of Campina Grande},
  year = 	 {2014},
}

@InCollection{jml,
author = {G. Leavens and A. Baker and C. Ruby},
title = {{JML: A Notation for Detailed Design}},
booktitle = {Behavioral Specifications for Businesses and Systems},
publisher = {Springer US},
year = {1999},
editor = {H. Kilov, B. Rumpe and W. Harvey},
chapter = {12},
pages ={175--188},
}

@inproceedings{Leavens10,
 author = {Leavens, G.},
 title = {The Future of Library Specification},
 booktitle = {Proceedings of the FSE/SDP Workshop on Future of Software Engineering Research},
 year = {2010},
 pages = {211--216},
 publisher = {ACM},
}

@article{dbc,
  title={Applying "Design by Contract"},
  author={Meyer, B.},
  journal={Computer},
  volume={25},
  number={10},
  pages={40--51},
  year={1992},
  publisher={IEEE}
}

@article{Rosenblum,
abstract = {Embedded assertions have long been recognized as a$\backslash$npotentially powerful tool for automatic runtime$\backslash$ndetection of software faults during debugging,$\backslash$ntesting and maintenance. However, they have seen$\backslash$nlittle widespread use in practice because previous$\backslash$nassertion processing tools did not integrate easily$\backslash$nwith existing programming environments, and it is$\backslash$nnot well understood what kinds of assertions are$\backslash$nmost effective at detecting software faults. The$\backslash$nauthor describes experience using an assertion$\backslash$nprocessing tool that was built to address the$\backslash$nconcerns of ease-of-use and effectiveness. The tool$\backslash$nis called APP, an Annotation Pre-Processor for C$\backslash$nprograms developed in UNIX-based development$\backslash$nenvironments. APP has been used to develop a number$\backslash$nof software systems over three years. Based on this$\backslash$nexperience, the author presents a classification of$\backslash$nthe assertions that were most effective at detecting$\backslash$nfaults. While the assertions that are described$\backslash$nguard against many common kinds of faults and$\backslash$nerrors, the very commonness of such faults$\backslash$ndemonstrates the need for an explicit, high-level,$\backslash$nautomatically checkable specification of required$\backslash$nbehavior.},
author = {Rosenblum, D.S.},
doi = {10.1109/ICSE.1992.753493},
file = {:Users/tiagomassoni/Dropbox/leituras/papers/dbc/Rosenblum - 1992 - Towards A Method Of Programming With Assertions.pdf:pdf},
isbn = {0-8791-504-6},
issn = {0270-5257},
journal = {International Conference on Software Engineering},
mendeley-groups = {Ecoop contractJdoc},
pages = {92--104},
title = {{Towards A Method Of Programming With Assertions}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=753493}
}


@inproceedings{sac2017,
  author    = {Alysson Milanez and
               Bianca Lima and
               Jos{\'{e}} Ferreira and
               Tiago Massoni},
  title     = {Nonconformance between programs and contracts: a study on C{\#}/code
               contracts open source systems},
  booktitle = {Proceedings of the Symposium on Applied Computing, {SAC} 2017, Marrakech,
               Morocco, April 3-7, 2017},
  pages     = {1219--1224},
  year      = {2017},
  crossref  = {DBLP:conf/sac/2017},
  url       = {https://doi.org/10.1145/3019612.3019779},
  doi       = {10.1145/3019612.3019779},
  timestamp = {Wed, 05 Dec 2018 13:49:36 +0100},
  biburl    = {https://dblp.org/rec/bib/conf/sac/MilanezLFM17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{typeContracts,
 author = {Schiller, T. and Donohue, K. and Coward, F. and Ernst, M.},
 title = {Case Studies and Tools for Contract Specifications},
 booktitle = {International Conference on Software Engineering},
 year = {2014},
 pages = {596--607},
 publisher = {ACM},
}

@INPROCEEDINGS{atComment,
author={S. Tan and D. Marinov and L. Tan and G. Leavens},
booktitle={International Conference on Software Testing, Verification and Validation},
title={{@tComment: Testing Javadoc Comments to Detect Comment-Code Inconsistencies}},
year={2012},
pages={260-269},
publisher = {IEEE Computer Society},
}

@INPROCEEDINGS{documentingPattern,
author={M. Torchiano},
booktitle={Software Maintenance, 2002. Proceedings. International Conference on},
title={{Documenting pattern use in Java programs}},
year={2002},
pages={230-233},
}

@misc{javadoc-oracle,
  title = {Javadoc Technology},
  howpublished = {\url{https://docs.oracle.com/javase/8/docs/technotes/guides/javadoc/index.html}},
  note = {Accessed: 2018-01-10}
}

@book{java-spec,
 author = {Gosling, James and Joy, Bill and Steele, Guy L. and Bracha, Gilad and Buckley, Alex},
 title = {The Java Language Specification, Java SE 8 Edition},
 year = {2014},
 isbn = {013390069X, 9780133900699},
 edition = {1st},
 publisher = {Addison-Wesley Professional},
} 


@incollection{Price2010,
abstract = {Open coding is an essential methodological tool for qualitative data analysis that was introduced in grounded theory research. Open coding refers to the initial interpretive process by which raw research data are first systematically analyzed and categorized.},
author = {Price, Jason Matthew Cameron},
booktitle = {Encyclopedia of Case Study Research},
doi = {10.4135/9781412957397.n55},
isbn = {9781412956703},
mendeley-groups = {Ecoop contractJdoc},
title = {{Coding: Open Coding}},
year = {2010}
}


@inproceedings{Hao2013,
abstract = {In software evolution, developers typically need to identify whether the failure of a test is due to a bug in the source code under test or the obsoleteness of the test code when they execute a test suite. Only after finding the cause of a failure can developers determine whether to fix the bug or repair the obsolete test. Researchers have proposed several techniques to automate test repair. However, test-repair techniques typically assume that test failures are always due to obsolete tests. Thus, such techniques may not be applicable in real world software evolution when developers do not know whether the failure is due to a bug or an obsolete test. To know whether the cause of a test failure lies in the source code under test or in the test code, we view this problem as a classification problem and propose an automatic approach based on machine learning. Specifically, we target Java software using the JUnit testing framework and collect a set of features that may be related to failures of tests. Using this set of features, we adopt the Best-first Decision Tree Learning algorithm to train a classifier with some existing regression test failures as training instances. Then, we use the classifier to classify future failed tests. Furthermore, we evaluated our approach using two Java programs in three scenarios (within the same version, within different versions of a program, and between different programs), and found that our approach can effectively classify the causes of failed tests. {\textcopyright} 2013 Springer-Verlag Berlin Heidelberg.},
author = {Hao, Dan and Lan, Tian and Zhang, Hongyu and Guo, Chao and Zhang, Lu},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-642-39038-8-25},
isbn = {9783642390371},
issn = {03029743},
mendeley-groups = {Ecoop contractJdoc},
title = {{Is this a bug or an obsolete test?}},
year = {2013}
}
